{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75bbba65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ 4ê°œ í´ë˜ìŠ¤: ['comedones', 'pustules', 'papules', 'folliculitis']\n",
      "------------------------------------------------------------\n",
      "ë°ì´í„°ì…‹ íŒŒì¼ ê²½ë¡œ ë¡œë“œ ì¤‘...\n",
      "\n",
      "ğŸ“Š ë°ì´í„°ì…‹ ìš”ì•½: ì „ì²´ 2228ì¥\n",
      "  - í•™ìŠµ ë°ì´í„°: 1559ì¥\n",
      "  - ê²€ì¦ ë°ì´í„°: 334ì¥\n",
      "  - í…ŒìŠ¤íŠ¸ ë°ì´í„°: 335ì¥\n",
      "\n",
      "âš–ï¸ ê³„ì‚°ëœ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜:\n",
      "  - comedones: 2.165\n",
      "  - pustules: 1.107\n",
      "  - papules: 0.430\n",
      "  - folliculitis: 3.248\n",
      "------------------------------------------------------------\n",
      "Found 1559 validated image filenames belonging to 4 classes.\n",
      "Found 334 validated image filenames belonging to 4 classes.\n",
      "\n",
      "--- Phase 1: Feature Extraction (EfficientNet ë™ê²°) ì‹œì‘ ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeongjin/Library/Python/3.9/lib/python/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.2287 - loss: 1.7015\n",
      "Epoch 1: val_accuracy improved from -inf to 0.22187, saving model to acne_classifier_efficientnetb0_best.keras\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 382ms/step - accuracy: 0.2288 - loss: 1.7001 - val_accuracy: 0.2219 - val_loss: 1.7427 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m 1/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m12s\u001b[0m 259ms/step - accuracy: 0.1875 - loss: 1.5932"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeongjin/Library/Python/3.9/lib/python/site-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_accuracy improved from 0.22187 to 0.23125, saving model to acne_classifier_efficientnetb0_best.keras\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 0.1875 - loss: 1.5932 - val_accuracy: 0.2313 - val_loss: 1.6842 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - accuracy: 0.2225 - loss: 1.5262\n",
      "Epoch 3: val_accuracy did not improve from 0.23125\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 404ms/step - accuracy: 0.2226 - loss: 1.5266 - val_accuracy: 0.2188 - val_loss: 1.6306 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m 1/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m15s\u001b[0m 330ms/step - accuracy: 0.1562 - loss: 1.4825\n",
      "Epoch 4: val_accuracy did not improve from 0.23125\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.1562 - loss: 1.4825 - val_accuracy: 0.2281 - val_loss: 1.5963 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.2209 - loss: 1.5635\n",
      "Epoch 5: val_accuracy did not improve from 0.23125\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 369ms/step - accuracy: 0.2209 - loss: 1.5631 - val_accuracy: 0.2281 - val_loss: 1.4761 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m 1/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m12s\u001b[0m 263ms/step - accuracy: 0.3750 - loss: 1.6158\n",
      "Epoch 6: val_accuracy did not improve from 0.23125\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.3750 - loss: 1.6158 - val_accuracy: 0.2250 - val_loss: 1.4956 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.2208 - loss: 1.5151\n",
      "Epoch 7: val_accuracy did not improve from 0.23125\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 365ms/step - accuracy: 0.2208 - loss: 1.5153 - val_accuracy: 0.2250 - val_loss: 1.5874 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m 1/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m13s\u001b[0m 292ms/step - accuracy: 0.3125 - loss: 1.6705\n",
      "Epoch 8: val_accuracy did not improve from 0.23125\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.3125 - loss: 1.6705 - val_accuracy: 0.2219 - val_loss: 1.5924 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.2332 - loss: 1.5329\n",
      "Epoch 9: val_accuracy improved from 0.23125 to 0.23438, saving model to acne_classifier_efficientnetb0_best.keras\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 375ms/step - accuracy: 0.2331 - loss: 1.5327 - val_accuracy: 0.2344 - val_loss: 1.4680 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m 1/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m12s\u001b[0m 274ms/step - accuracy: 0.1875 - loss: 1.7106\n",
      "Epoch 10: val_accuracy did not improve from 0.23438\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.1875 - loss: 1.7106 - val_accuracy: 0.2281 - val_loss: 1.4719 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "\n",
      "--- Phase 2: Fine-Tuning (ì „ì²´ EfficientNet ë ˆì´ì–´ í•´ë™) ì‹œì‘ ---\n",
      "Epoch 11/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1645 - loss: 2.4225\n",
      "Epoch 11: val_accuracy did not improve from 0.23438\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.1649 - loss: 2.4196 - val_accuracy: 0.2281 - val_loss: 1.3959 - learning_rate: 1.0000e-05\n",
      "Epoch 12/40\n",
      "\u001b[1m 1/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1:38\u001b[0m 2s/step - accuracy: 0.1562 - loss: 2.0458\n",
      "Epoch 12: val_accuracy did not improve from 0.23438\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.1562 - loss: 2.0458 - val_accuracy: 0.2250 - val_loss: 1.4028 - learning_rate: 1.0000e-05\n",
      "Epoch 13/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2497 - loss: 1.8300\n",
      "Epoch 13: val_accuracy did not improve from 0.23438\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.2498 - loss: 1.8300 - val_accuracy: 0.2313 - val_loss: 1.3665 - learning_rate: 1.0000e-05\n",
      "Epoch 14/40\n",
      "\u001b[1m 1/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1:24\u001b[0m 2s/step - accuracy: 0.1875 - loss: 1.2010\n",
      "Epoch 14: val_accuracy did not improve from 0.23438\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.1875 - loss: 1.2010 - val_accuracy: 0.2281 - val_loss: 1.3668 - learning_rate: 1.0000e-05\n",
      "Epoch 15/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2925 - loss: 1.6704\n",
      "Epoch 15: val_accuracy did not improve from 0.23438\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.2925 - loss: 1.6702 - val_accuracy: 0.2250 - val_loss: 1.3688 - learning_rate: 1.0000e-05\n",
      "Epoch 16/40\n",
      "\u001b[1m 1/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1:05\u001b[0m 1s/step - accuracy: 0.3438 - loss: 1.6936\n",
      "Epoch 16: val_accuracy did not improve from 0.23438\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - accuracy: 0.3438 - loss: 1.6936 - val_accuracy: 0.2250 - val_loss: 1.3685 - learning_rate: 1.0000e-05\n",
      "Epoch 17/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3077 - loss: 1.6663\n",
      "Epoch 17: val_accuracy did not improve from 0.23438\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.3079 - loss: 1.6655 - val_accuracy: 0.2250 - val_loss: 1.3722 - learning_rate: 1.0000e-05\n",
      "Epoch 18/40\n",
      "\u001b[1m 1/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1:09\u001b[0m 1s/step - accuracy: 0.3750 - loss: 1.3697\n",
      "Epoch 18: val_accuracy did not improve from 0.23438\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.3750 - loss: 1.3697 - val_accuracy: 0.2281 - val_loss: 1.3677 - learning_rate: 1.0000e-05\n",
      "Epoch 19/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3470 - loss: 1.5361\n",
      "Epoch 19: val_accuracy did not improve from 0.23438\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 0.3470 - loss: 1.5358 - val_accuracy: 0.2125 - val_loss: 1.3672 - learning_rate: 1.0000e-05\n",
      "Epoch 20/40\n",
      "\u001b[1m 1/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1:04\u001b[0m 1s/step - accuracy: 0.3438 - loss: 1.5551\n",
      "Epoch 20: val_accuracy did not improve from 0.23438\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.3438 - loss: 1.5551 - val_accuracy: 0.2188 - val_loss: 1.3652 - learning_rate: 1.0000e-05\n",
      "Epoch 21/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3180 - loss: 1.5175\n",
      "Epoch 21: val_accuracy did not improve from 0.23438\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.3183 - loss: 1.5171 - val_accuracy: 0.2219 - val_loss: 1.3734 - learning_rate: 1.0000e-05\n",
      "Epoch 22/40\n",
      "\u001b[1m 1/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1:21\u001b[0m 2s/step - accuracy: 0.3750 - loss: 0.9932\n",
      "Epoch 22: val_accuracy did not improve from 0.23438\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.3750 - loss: 0.9932 - val_accuracy: 0.2156 - val_loss: 1.3776 - learning_rate: 1.0000e-05\n",
      "Epoch 23/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3649 - loss: 1.3984\n",
      "Epoch 23: val_accuracy did not improve from 0.23438\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.3650 - loss: 1.3989 - val_accuracy: 0.2313 - val_loss: 1.3726 - learning_rate: 1.0000e-05\n",
      "Epoch 24/40\n",
      "\u001b[1m 1/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1:05\u001b[0m 1s/step - accuracy: 0.3125 - loss: 1.1564\n",
      "Epoch 24: val_accuracy did not improve from 0.23438\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.3125 - loss: 1.1564 - val_accuracy: 0.2188 - val_loss: 1.3785 - learning_rate: 1.0000e-05\n",
      "Epoch 25/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3682 - loss: 1.4006\n",
      "Epoch 25: val_accuracy did not improve from 0.23438\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.3683 - loss: 1.4002 - val_accuracy: 0.2219 - val_loss: 1.3851 - learning_rate: 1.0000e-05\n",
      "Epoch 26/40\n",
      "\u001b[1m 1/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1:05\u001b[0m 1s/step - accuracy: 0.3125 - loss: 1.2198\n",
      "Epoch 26: val_accuracy did not improve from 0.23438\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.3125 - loss: 1.2198 - val_accuracy: 0.2250 - val_loss: 1.3796 - learning_rate: 1.0000e-05\n",
      "Epoch 27/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3788 - loss: 1.4278\n",
      "Epoch 27: val_accuracy improved from 0.23438 to 0.27812, saving model to acne_classifier_efficientnetb0_best.keras\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.3788 - loss: 1.4267 - val_accuracy: 0.2781 - val_loss: 1.3256 - learning_rate: 1.0000e-05\n",
      "Epoch 28/40\n",
      "\u001b[1m 1/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1:05\u001b[0m 1s/step - accuracy: 0.5938 - loss: 1.2408\n",
      "Epoch 28: val_accuracy improved from 0.27812 to 0.29063, saving model to acne_classifier_efficientnetb0_best.keras\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.5938 - loss: 1.2408 - val_accuracy: 0.2906 - val_loss: 1.3217 - learning_rate: 1.0000e-05\n",
      "Epoch 29/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4004 - loss: 1.3434\n",
      "Epoch 29: val_accuracy improved from 0.29063 to 0.33750, saving model to acne_classifier_efficientnetb0_best.keras\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.4004 - loss: 1.3433 - val_accuracy: 0.3375 - val_loss: 1.2617 - learning_rate: 1.0000e-05\n",
      "Epoch 30/40\n",
      "\u001b[1m 1/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1:05\u001b[0m 1s/step - accuracy: 0.3750 - loss: 1.3104\n",
      "Epoch 30: val_accuracy improved from 0.33750 to 0.34375, saving model to acne_classifier_efficientnetb0_best.keras\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.3750 - loss: 1.3104 - val_accuracy: 0.3438 - val_loss: 1.2562 - learning_rate: 1.0000e-05\n",
      "Epoch 31/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3866 - loss: 1.3672\n",
      "Epoch 31: val_accuracy improved from 0.34375 to 0.43125, saving model to acne_classifier_efficientnetb0_best.keras\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.3866 - loss: 1.3665 - val_accuracy: 0.4313 - val_loss: 1.1238 - learning_rate: 1.0000e-05\n",
      "Epoch 32/40\n",
      "\u001b[1m 1/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1:30\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.9186\n",
      "Epoch 32: val_accuracy did not improve from 0.43125\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.5625 - loss: 0.9186 - val_accuracy: 0.4281 - val_loss: 1.1273 - learning_rate: 1.0000e-05\n",
      "Epoch 33/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3906 - loss: 1.3021\n",
      "Epoch 33: val_accuracy improved from 0.43125 to 0.47500, saving model to acne_classifier_efficientnetb0_best.keras\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.3908 - loss: 1.3022 - val_accuracy: 0.4750 - val_loss: 1.0969 - learning_rate: 1.0000e-05\n",
      "Epoch 34/40\n",
      "\u001b[1m 1/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1:07\u001b[0m 1s/step - accuracy: 0.5000 - loss: 0.9044\n",
      "Epoch 34: val_accuracy improved from 0.47500 to 0.48438, saving model to acne_classifier_efficientnetb0_best.keras\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.5000 - loss: 0.9044 - val_accuracy: 0.4844 - val_loss: 1.0931 - learning_rate: 1.0000e-05\n",
      "Epoch 35/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4039 - loss: 1.2577\n",
      "Epoch 35: val_accuracy improved from 0.48438 to 0.52500, saving model to acne_classifier_efficientnetb0_best.keras\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.4044 - loss: 1.2574 - val_accuracy: 0.5250 - val_loss: 1.0621 - learning_rate: 1.0000e-05\n",
      "Epoch 36/40\n",
      "\u001b[1m 1/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1:39\u001b[0m 2s/step - accuracy: 0.5625 - loss: 1.4669\n",
      "Epoch 36: val_accuracy did not improve from 0.52500\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.5625 - loss: 1.4669 - val_accuracy: 0.5156 - val_loss: 1.0623 - learning_rate: 1.0000e-05\n",
      "Epoch 37/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4348 - loss: 1.2944\n",
      "Epoch 37: val_accuracy improved from 0.52500 to 0.55000, saving model to acne_classifier_efficientnetb0_best.keras\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.4348 - loss: 1.2938 - val_accuracy: 0.5500 - val_loss: 1.0470 - learning_rate: 1.0000e-05\n",
      "Epoch 38/40\n",
      "\u001b[1m 1/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1:46\u001b[0m 2s/step - accuracy: 0.3750 - loss: 1.2621\n",
      "Epoch 38: val_accuracy did not improve from 0.55000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.3750 - loss: 1.2621 - val_accuracy: 0.5406 - val_loss: 1.0577 - learning_rate: 1.0000e-05\n",
      "Epoch 39/40\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4378 - loss: 1.2431\n",
      "Epoch 39: val_accuracy improved from 0.55000 to 0.56563, saving model to acne_classifier_efficientnetb0_best.keras\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.4382 - loss: 1.2430 - val_accuracy: 0.5656 - val_loss: 1.0513 - learning_rate: 1.0000e-05\n",
      "Epoch 40/40\n",
      "\u001b[1m 1/48\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1:15\u001b[0m 2s/step - accuracy: 0.3438 - loss: 0.9489\n",
      "Epoch 40: val_accuracy did not improve from 0.56563\n",
      "\u001b[1m48/48\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - accuracy: 0.3438 - loss: 0.9489 - val_accuracy: 0.5656 - val_loss: 1.0491 - learning_rate: 1.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "\n",
      "--- ìµœì¢… ëª¨ë¸ ë¡œë“œ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€ ---\n",
      "Found 335 validated image filenames belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeongjin/Library/Python/3.9/lib/python/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 249ms/step - accuracy: 0.6058 - loss: 0.9885\n",
      "\u001b[1m11/11\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 323ms/step\n",
      "\n",
      "======================================================================\n",
      "                    ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\n",
      "======================================================================\n",
      "\n",
      "ğŸ¯ ëª¨ë¸ ì„±ëŠ¥:\n",
      "  - ìµœì¢… Test Accuracy: 0.5731\n",
      "  - ìµœì¢… Test Loss: 1.0007\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   comedones       0.39      0.51      0.44        39\n",
      "    pustules       0.00      0.00      0.00        25\n",
      "     papules       0.88      0.58      0.70       195\n",
      "folliculitis       0.37      0.76      0.50        76\n",
      "\n",
      "    accuracy                           0.57       335\n",
      "   macro avg       0.41      0.47      0.41       335\n",
      "weighted avg       0.64      0.57      0.58       335\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[ 20   0   3  16]\n",
      " [  9   0   3  13]\n",
      " [ 13   0 114  68]\n",
      " [  9   0   9  58]]\n",
      "\n",
      "ğŸ“ ìµœì¢… ëª¨ë¸ì´ acne_classifier_efficientnetb0_best.kerasì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeongjin/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jeongjin/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jeongjin/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import json\n",
    "\n",
    "# --- 1. í™˜ê²½ ì„¤ì • ë° ê²½ë¡œ ì§€ì • ---\n",
    "# ğŸš¨ ì‚¬ìš©ì ì„¤ì •: ë°ì´í„°ì…‹ í´ë” ê²½ë¡œë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.\n",
    "DATA_DIR = './data/image/'\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "RANDOM_SEED = 42\n",
    "EPOCHS = 40  # ì´ ì—í¬í¬ (Phase 1 + Phase 2)\n",
    "MODEL_NAME = 'acne_classifier_efficientnetb0'\n",
    "model_path = f'{MODEL_NAME}_best.keras'\n",
    "\n",
    "# 4ê°œ í´ë˜ìŠ¤ ì •ì˜ (Normal ì œì™¸)\n",
    "CLASSES = ['comedones', 'pustules', 'papules', 'folliculitis']\n",
    "num_classes = len(CLASSES)\n",
    "\n",
    "print(f\"ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ {num_classes}ê°œ í´ë˜ìŠ¤: {CLASSES}\")\n",
    "print(\"---\" * 20)\n",
    "\n",
    "# --- 2. ë°ì´í„° ë¡œë“œ ë° ë¶„í•  (ë¶ˆê· í˜• í•´ì†Œ í¬í•¨) ---\n",
    "\n",
    "X_paths = []  # ì´ë¯¸ì§€ ê²½ë¡œ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "Y_labels = [] # ë¼ë²¨ ì¸ë±ìŠ¤ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "print(\"ë°ì´í„°ì…‹ íŒŒì¼ ê²½ë¡œ ë¡œë“œ ì¤‘...\")\n",
    "for class_index, class_name in enumerate(CLASSES):\n",
    "    class_path = os.path.join(DATA_DIR, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        print(f\"ê²½ê³ : ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {class_path}\")\n",
    "        continue\n",
    "    for img_name in os.listdir(class_path):\n",
    "        if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            X_paths.append(os.path.join(class_path, img_name))\n",
    "            Y_labels.append(class_index)\n",
    "\n",
    "X_paths = np.array(X_paths)\n",
    "Y_labels = np.array(Y_labels)\n",
    "\n",
    "if len(X_paths) == 0:\n",
    "    print(\"ğŸš¨ ì˜¤ë¥˜: ë°ì´í„°ì…‹ í´ë”ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "    exit()\n",
    "\n",
    "# 1. Stratified Split: í´ë˜ìŠ¤ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©° í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• \n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(\n",
    "    X_paths, Y_labels, test_size=0.3, random_state=RANDOM_SEED, stratify=Y_labels\n",
    ")\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(\n",
    "    X_temp, Y_temp, test_size=0.5, random_state=RANDOM_SEED, stratify=Y_temp\n",
    ")\n",
    "\n",
    "# 2. í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° (í•™ìŠµ ë¶ˆê· í˜• ë³´ì •)\n",
    "class_weights_array = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(Y_train),\n",
    "    y=Y_train\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights_array))\n",
    "\n",
    "print(f\"\\nğŸ“Š ë°ì´í„°ì…‹ ìš”ì•½: ì „ì²´ {len(X_paths)}ì¥\")\n",
    "print(f\"  - í•™ìŠµ ë°ì´í„°: {len(X_train)}ì¥\")\n",
    "print(f\"  - ê²€ì¦ ë°ì´í„°: {len(X_val)}ì¥\")\n",
    "print(f\"  - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ì¥\")\n",
    "print(\"\\nâš–ï¸ ê³„ì‚°ëœ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜:\")\n",
    "for i, weight in class_weights.items():\n",
    "    print(f\"  - {CLASSES[i]}: {weight:.3f}\")\n",
    "print(\"---\" * 20)\n",
    "\n",
    "\n",
    "# 3. Keras Generatorìš© DataFrame ìƒì„±\n",
    "def create_dataframe(X_paths, Y_indices, classes):\n",
    "    df = pd.DataFrame({'filename': X_paths, 'class_index': Y_indices})\n",
    "    df['class'] = df['class_index'].apply(lambda x: classes[x])\n",
    "    return df\n",
    "\n",
    "train_df = create_dataframe(X_train, Y_train, CLASSES)\n",
    "val_df = create_dataframe(X_val, Y_val, CLASSES)\n",
    "\n",
    "# 4. ì´ë¯¸ì§€ ë°ì´í„° ì œë„ˆë ˆì´í„° ì„¤ì •\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, x_col='filename', y_col='class', target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE, class_mode='categorical', seed=RANDOM_SEED\n",
    ")\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    val_df, x_col='filename', y_col='class', target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE, class_mode='categorical', seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "\n",
    "# --- 3. ëª¨ë¸ ì •ì˜ ë° ì½œë°± ì„¤ì • ---\n",
    "\n",
    "def build_model(num_classes):\n",
    "    base_model = EfficientNetB0(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "    )\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "model = build_model(num_classes)\n",
    "\n",
    "# ì½œë°± ì„¤ì • (ModelCheckpointë¥¼ í†µí•œ ìµœì  ëª¨ë¸ ì €ì¥ í•„ìˆ˜)\n",
    "callbacks = [\n",
    "    # 1. ê°€ì¥ ë†’ì€ val_accuracyë¥¼ ê¸°ë¡í•œ ì‹œì ì˜ ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥\n",
    "    ModelCheckpoint(\n",
    "        filepath=model_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    # 2. val_lossê°€ 8ë²ˆì˜ ì—í¬í¬ ë™ì•ˆ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ í•™ìŠµ ì¢…ë£Œ (patience ì™„í™”)\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=8,\n",
    "        mode='min',\n",
    "        verbose=1,\n",
    "        restore_best_weights=True # ìµœì  ê°€ì¤‘ì¹˜ ë³µêµ¬\n",
    "    ),\n",
    "    # 3. val_lossê°€ 5ë²ˆì˜ ì—í¬í¬ ë™ì•ˆ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ í•™ìŠµë¥  ê°ì†Œ\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        min_lr=0.00001,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# --- 4. í•™ìŠµ ì‹œì‘: Phase 1 (Feature Extraction) ---\n",
    "\n",
    "print(\"\\n--- Phase 1: Feature Extraction (EfficientNet ë™ê²°) ì‹œì‘ ---\")\n",
    "\n",
    "# EfficientNet ë ˆì´ì–´ ë™ê²°\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "# ìµœìƒë‹¨ ì»¤ìŠ¤í…€ ë ˆì´ì–´ë§Œ í•™ìŠµ (ë§ˆì§€ë§‰ Dense ë ˆì´ì–´)\n",
    "for layer in model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), # ë¹„êµì  ë†’ì€ í•™ìŠµë¥ \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_phase1 = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=10, # ì´ˆê¸° 10 ì—í¬í¬\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights, # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- 5. í•™ìŠµ ì‹œì‘: Phase 2 (Fine-Tuning) ---\n",
    "\n",
    "print(\"\\n--- Phase 2: Fine-Tuning (ì „ì²´ EfficientNet ë ˆì´ì–´ í•´ë™) ì‹œì‘ ---\")\n",
    "\n",
    "# ì „ì²´ ë ˆì´ì–´ ë™ê²° í•´ì œ\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), # ë§¤ìš° ë‚®ì€ í•™ìŠµë¥ \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_phase2 = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS, # ì´ ì—í¬í¬ê¹Œì§€\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights, # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©\n",
    "    initial_epoch=history_phase1.epoch[-1] + 1, # Phase 1 ëë‚œ ë‹¤ìŒ ì—í¬í¬ë¶€í„° ì‹œì‘\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- 6. ìµœì¢… í‰ê°€ ë° ë¦¬í¬íŠ¸ ---\n",
    "\n",
    "print(\"\\n--- ìµœì¢… ëª¨ë¸ ë¡œë“œ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€ ---\")\n",
    "\n",
    "# ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì•˜ë˜ ëª¨ë¸ ë¡œë“œ\n",
    "model.load_weights(model_path)\n",
    "\n",
    "test_df = create_dataframe(X_test, Y_test, CLASSES)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df, x_col='filename', y_col='class', target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False\n",
    ")\n",
    "\n",
    "val_loss, val_acc = model.evaluate(test_generator, verbose=1)\n",
    "\n",
    "# ì˜ˆì¸¡ ë° ë¦¬í¬íŠ¸\n",
    "Y_pred = model.predict(test_generator)\n",
    "y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" \" * 20 + \"ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nğŸ¯ ëª¨ë¸ ì„±ëŠ¥:\")\n",
    "print(f\"  - ìµœì¢… Test Accuracy: {val_acc:.4f}\")\n",
    "print(f\"  - ìµœì¢… Test Loss: {val_loss:.4f}\")\n",
    "\n",
    "# ë¶„ë¥˜ ë¦¬í¬íŠ¸ ì¶œë ¥ (Precision, Recall, F1-Score í™•ì¸)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(test_generator.classes, y_pred_classes, target_names=CLASSES))\n",
    "\n",
    "# í˜¼ë™ í–‰ë ¬ ì¶œë ¥ (ëª¨ë¸ì˜ ì˜¤ë¶„ë¥˜ íŒ¨í„´ í™•ì¸)\n",
    "conf_matrix = confusion_matrix(test_generator.classes, y_pred_classes)\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# ìµœì¢… í•™ìŠµ ì •ë³´ ì €ì¥ (ì„ íƒ ì‚¬í•­)\n",
    "model_info = {\n",
    "    'classes': CLASSES,\n",
    "    'test_accuracy': float(val_acc),\n",
    "    'test_loss': float(val_loss),\n",
    "    'class_weights': class_weights,\n",
    "    'model_path': model_path\n",
    "}\n",
    "with open('model_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=4)\n",
    "print(f\"\\nğŸ“ ìµœì¢… ëª¨ë¸ì´ {model_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
